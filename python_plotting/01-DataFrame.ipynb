{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "[Pandas](https://pandas.pydata.org/) is a newer package built on top of NumPy library, which in practice means that most of the methods defined for Numpy Arrays apply to Pandas Series/DataFrames. \n",
    "\n",
    "Pandas provides an efficient implementation of a [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html), which is a collection of [`Series`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html); The `DataFrame` is the way Pandas represents a table, and `Series` is the data-structure Pandas use to represent a column.\n",
    "\n",
    "`DataFrame`s are essentially multidimensional arrays with attached row and column labels, and often with heterogeneous types and/or missing data. \n",
    "\n",
    "Reference & useful links: [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/index.html), [Plotting and Programming in Python](https://swcarpentry.github.io/python-novice-gapminder/), [Getting started tutorials](https://pandas.pydata.org/docs/getting_started/intro_tutorials/index.html)\n",
    "\n",
    "# Loading data with Pandas\n",
    "\n",
    "Load Pandas with `import pandas as pd`. The **alias** `pd` is commonly used to refer to the Pandas library in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the package's built-in documentation, we can use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a Comma Separated Values (CSV) data file with `pd.read_csv`\n",
    "\n",
    "* Argument is the name of the file to be read.\n",
    "* Returns a dataframe that you can assign to a variable\n",
    "\n",
    "The comma-separated-value data here is a periodic table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table = pd.read_csv(\"https://gist.githubusercontent.com/GoodmanSciences/c2dd862cd38f21b0ad36b8f96b4bf1ee/raw/1d92663004489a5b6926e944c1b3d9ec5c40900e/Periodic%2520Table%2520of%2520Elements.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use argument `header` to set row number(s) containing column labels and marking the start of the data (zero-indexed).\n",
    "* Use argument `index_col` to set a column's values as row headings (index).\n",
    "\n",
    "### Exercise 1: \n",
    "\n",
    "Try to read the data from a downloaded file rather than from an online resource, and set the `Symbol` column as row labels. Please use the csv file provided in the data/ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: File structure\n",
    "\n",
    "The data for the current project is stored in a file called `periodic_table.csv`, which is located in a folder called `data/`.\n",
    "\n",
    "```LaTex\n",
    "python_plotting/\n",
    "├──data/\n",
    "│  └──periodic_table.csv\n",
    "├──00-Recap-on-Numpy.ipynb\n",
    "├──01-DataFrame.ipynb\n",
    "├──02-Data-Visualization.ipynb\n",
    "└──...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing Pandas Dataframes: Tabular data\n",
    "\n",
    "* Pandas is a widely-used Python library for statistics, particularly on tabular data.\n",
    "* Borrows many features from R's dataframes.\n",
    "    * A 2-dimensional table whose columns have names and potentially have different data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The columns in a dataframe are the observed variables, and the rows are the observations.\n",
    "* Using descriptive dataframe names helps us distinguish between multiple dataframes so we won’t accidentally overwrite a dataframe or read from the wrong one.\n",
    "\n",
    "## Use `shape` to find the shape of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(periodic_table.shape)\n",
    "print(periodic_table.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `DataFrame.T` to transpose a DataFrame\n",
    "\n",
    "* Sometimes want to treat columns as rows and vice versa.\n",
    "* Transpose (written `.T`) doesn't copy the data, just changes the program's view of it.\n",
    "* Like `columns`, it is a member variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2:\n",
    "\n",
    "After reading the data, use `help(periodic_table.head)` and `help(periodic_table.tail)` to find out what `DataFrame.head` and `DataFrame.tail` do.\n",
    "\n",
    "1. What method call will display the first three rows of this data?\n",
    "2. What method call will display the last three columns of this data? (Hint: you may need to change your view of the data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DataFrame.columns` variable stores the column labels of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DataFrame.index` variable stores the index (row labels) of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `DataFrame.set_index[..., ...]` to set a column’s values as row headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.set_index('Element', inplace=True, drop=False)\n",
    "periodic_table.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting values\n",
    "\n",
    "To access a value at the position `[i,j]` of a DataFrame, we have two options, depending on what is the meaning of *i* in use. Remember that a DataFrame provides an *index* as a way to identify the rows of the table; a row, then, has a position inside the table as well as a *label*, which uniquely identifies its *entry* in the DataFrame.\n",
    "\n",
    "## Use `DataFrame.iloc[..., ...]` to select values by their (entry) position\n",
    "\n",
    "Can specify location by numerical index analogously to 2D version of character selection in strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.iloc[0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use `DataFrame.loc[..., ...]` to select values by their (entry) label\n",
    "\n",
    "Can specify location by row and/or column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.loc[\"Hydrogen\", \"Symbol\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the individual Series (columns) of the DataFrame (attibute-style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.Symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the individual data\n",
    "periodic_table.Symbol['Carbon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalently, via dictionary-style indexing\n",
    "periodic_table['Symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select multiple columns\n",
    "periodic_table[['AtomicNumber', 'Symbol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the individual data\n",
    "periodic_table['Symbol']['Carbon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select multiple columns or rows\n",
    "\n",
    "### Slicing by implicit integer index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivalently, using `iloc` for integer-location based indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing by explicit/named index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table['Hydrogen':'Carbon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivalently, using `loc` for label-based indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.loc['Hydrogen':'Carbon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.iloc[0:5, 1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.loc['Hydrogen':'Carbon', 'Element':'AtomicMass']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3:  \n",
    "\n",
    "What's the difference between slicing with an explicit index and slicing with an implicit index?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select values or NaN using a Boolean mask\n",
    "\n",
    "Direct masking operations are interpreted row-wise rather than column-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table['AtomicMass'] < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table[(periodic_table['AtomicMass'] < 10) & (periodic_table['Density'] > 0.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: \n",
    "\n",
    "Please get data with melting point higher than boiling point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Data\n",
    "\n",
    "## Missing data in Pandas\n",
    "\n",
    "`None`: Pythonic missing data, which cannot be used in any arbitrary NumPy/Pandas array, but only in arrays with data type 'object' (i.e., arrays of Python objects).\n",
    "\n",
    "`NaN`: Missing numerical data (acronym for *Not a Number*), a special floating-point value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "example1 = np.array([0, 1, 2, 3])\n",
    "example2 = np.array([0, 1, None, 3])\n",
    "print(example1.dtype, example2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example2 + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "example3 = np.array([0, 1, np.nan, 3])\n",
    "print(example3.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example3 + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is built to handle `NaN` and `None` nearly interchangeable.\n",
    "\n",
    "## Detecting null values with `isna`\n",
    "\n",
    "We can use `isna` to generate a boolean mask indicating missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing null values with `dropna`\n",
    "\n",
    "We cannot drop single values from a DataFrame; we can only drop full rows or full columns. By default, `dropna` will drop all rows in which any null value is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can drop missing values along a different axis; axis=1 drops all columns containing a null value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.dropna(axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `subset` to specify labels along other axis to consider. For example, if you are dropping rows these would be a list of columns to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.dropna(subset=['Density']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.dropna(axis=1, subset=['Hydrogen']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping rows or columns with all missing values or a majority of missing values can be specified through the `how` or `thresh` parameters.\n",
    "\n",
    "### Exercise 5: \n",
    "\n",
    "Drop rows with nonmetal elements and print only the `Group` and `Nonmetal` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating data in the DataFrame\n",
    "\n",
    "## Create a new column\n",
    "\n",
    "Create a column with NumberofNeutrons + NumberofProtons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table['Core'] = periodic_table['NumberofNeutrons'] + periodic_table['NumberofProtons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the logic for creating the new column is more complex and requires a custom function, the [`apply`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html) method can be used.\n",
    "\n",
    "## Combining datasets\n",
    "\n",
    "Simple concatenation with `pd.concat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [{'A': i, 'B': 2 * i}\n",
    "     for i in range(3)]\n",
    "df1 = pd.DataFrame(d)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = [{'A': i, 'B': -i}\n",
    "     for i in range(3)]\n",
    "df2 = pd.DataFrame(d)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [{'A': i, 'C': -i}\n",
    "     for i in range(3)]\n",
    "df3 = pd.DataFrame(d)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should pay attention to how it works.\n",
    "\n",
    "# Aggregation and Grouping\n",
    "\n",
    "Pandas vectorizing methods and grouping operations are features that provide users much flexibility to analyse their data.\n",
    "\n",
    "## Simple Aggregation in Pandas\n",
    "\n",
    "Earlier, we explored some of the data aggregations available for NumPy arrays (sum, min, max). For a DataFrame, by default the aggregates return results within each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table['NumberofElectrons'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to all of the common aggregates, there is a convenience method `describe` that computes several common aggregates for each column and returns the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GroupBy: Split, Apply, Combine\n",
    "\n",
    "Simple aggregations can give you a flavor of your dataset, but often we would prefer to aggregate conditionally on some label or index: this is implemented in the so-called `groupby` operation. \n",
    "\n",
    "Here we'll look at the basics of *GroupBy* operations, where the \"apply\" is a summation aggregation (image adopted from [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/index.html)).\n",
    "\n",
    "![image](https://jakevdp.github.io/PythonDataScienceHandbook/figures/03.08-split-apply-combine.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This makes clear what the groupby accomplishes:\n",
    "\n",
    "* The *split* step involves breaking up and grouping a DataFrame depending on the value of the specified key.\n",
    "* The *apply* step involves computing some function, usually an aggregate, transformation, or filtering, within the individual groups.\n",
    "* The *combine* step merges the results of these operations into an output array.\n",
    "\n",
    "Group data in the periodic table by groups (families):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.groupby(['Group']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6:\n",
    "\n",
    "How to group data by periods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7:\n",
    "\n",
    "Calculate the average Atomic Mass of data grouped by Period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can specify a groupby using the names of table columns and compute other functions, such as the `sum`, `count`, `mean`, and `describe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodic_table.groupby(['Group'])['Density'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8:\n",
    "\n",
    "As well as the `read_csv` function for reading data from a file, Pandas provides a [`to_csv`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html) function to write dataframes to files. Applying what you’ve learned about reading from files, write one of your dataframes to a file called `processed.csv`. You can use help to get information on how to use `to_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "\n",
    "There are at least two ways of accessing a value or slice of a DataFrame: by name or index. However, there are many others. For example, a single column or row can be accessed either as a `DataFrame` or a `Series` object.\n",
    "\n",
    "Suggest different ways of doing the following operations on a DataFrame:\n",
    "\n",
    "1. Access a single column\n",
    "2. Access a single row\n",
    "3. Access an individual DataFrame element\n",
    "4. Access several columns\n",
    "5. Access several rows\n",
    "6. Access a subset of specific rows and columns\n",
    "7. Access a subset of row and column ranges\n",
    "\n",
    "Solutions are [here](https://swcarpentry.github.io/python-novice-gapminder/08-data-frames.html#many-ways-of-access)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
